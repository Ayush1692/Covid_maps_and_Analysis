getwd()
getwd()
setwd("C:/Users/kumar/Downloads/Courses/project/R/Assignment1")
townList <- read.csv("List_of_Towns.csv")
realEstate <- read.csv("Real_Estate_Sales_2014-2016.csv")
mergedData <- merge(x = townList,
y = realEstate,
by.x = "Town",
by.y = "Town")
summary(mergedData)
str(mergedData)
CheckMissingData <- mergedData[is.na(mergedData$DateRecorded),]
library("lubridate")
mergedData$DateRecorded = lubridate::mdy(mergedData$DateRecorded)
missingDataCheck1 <- mergedData[is.na(mergedData$DateRecorded),]
# We got 6 observations with missing values in DateRecorded column
missingDataCheck2 <- mergedData[is.na(mergedData$SaleAmount),]
# We got 5283 observations with missing values in SaleAmount column
missingDataCheck3 <- mergedData[is.na(mergedData$ResidentialType),]
# We got 11905 observations with missing values in ResidentialType column
missingDataCheck4 <- mergedData[is.na(mergedData$Address),]
###Question 3
#Replacing missing dateRecorded data
missingDataCheck1$DateRecorded = "01-01-2014"
#which(is.na(missingDataCheck1$DateRecorded))
missingDataCheck1$DateRecorded = lubridate::mdy(missingDataCheck1$DateRecorded)
#Adding subset to the dataseet
clean = mergedData[is.na(mergedData$DateRecorded)==F,]
clean = clean[is.na(clean$SaleAmount)==F,]
#combining the subsets
mergedSetFinal = rbind(clean,missingDataCheck1,missingDataCheck2)
mergedSetFinal$PropertyValue = ifelse(mergedSetFinal$AssessedValue <= 300000,"LowRange",
ifelse(mergedSetFinal$AssessedValue > 800000,"HighRange","MidRange"))
###Question5 measure of central tendancy and variability
#Using describe function to get statistical values
salesAmountDesc = psych::describeBy(mergedSetFinal$SaleAmount)
salesAmountDesc
View(salesAmountDesc)
AssessedValDesc = psych::describeBy(mergedSetFinal$AssessedValue)
mergedSetFinal$populationValDesc = gsub(",","",mergedSetFinal$Population..in.2010.)
mergedSetFinal$populationValDesc1 = as.numeric(mergedSetFinal$populationValDesc)
populationValDesc2 = psych::describe(mergedSetFinal$populationValDesc1)
populationValDesc2
###Question5 measure of central tendancy and variability
#Using describe function to get statistical values
salesAmountDesc = psych::describe(mergedSetFinal$SaleAmount)
salesAmountDesc
AssessedValDesc = psych::describe(mergedSetFinal$AssessedValue)
AssessedValDesc
###Question 6
library(ggplot2)
par(mfrow=c(2,2))
# top left
plot(density(mergedSetFinal$ListYear, main="List Year", xlab = "List Year"))
# top right
hist(mergedSetFinal$ListYear, main="List Year",xlab = "List Year")
# bottom left
boxplot(mergedSetFinal$ListYear, main= "List Year", xlab = "List Year")
# bottom right
hist(mergedSetFinal$ListYear, xlab = "List Year")
lines(mergedSetFinal$ListYear,xlab = "List Year", type = "l",
col = "red" , lty = 2 , lwd = 1.5)
max(mergedSetFinal$AssessedValue)
###Question 7
install.packages("plyr")
library("plyr")
#To get the frequency table, I used count function to calculate # properties per town
frequencyTown = count(mergedSetFinal, "Town")
frequencyTown
#Multidimensional frequency table
#Again using count function to get the multidimensional frequency table
multiDimFreq = count(mergedSetFinal, c('Town','County','ListYear'))
multiDimFreq
#Contingency table
tableC = table(mergedSetFinal$PropertyValue)
tableC
#tablec gives the count per category, now we need percentage
#To calculate percentage, first I get the sum of the row
tableSum <- data.frame(rbind(tableC))
sum1 = tableSum$HighRange + tableSum$LowRange + tableSum$MidRange
#Calculating percentage per column by dividing each entry with sum
col1 = (tableSum$HighRange/sum1)*100
col2 = (tableSum$LowRange/sum1)*100
col3 = (tableSum$MidRange/sum1)*100
#Final table
finalTable <- cbind(col1, col2, col3)
finalTable
###Question 8
###Question 8
#The property value decreases slightly in year 2015 than 2014
###Question 8
#The property value decreases slightly in year 2015 than 2014
#And increases in 2016 again.
###Question 8
#The property value decreases slightly in year 2015 than 2014
#And increases in 2016 again.
#Thi might be due to reduction in the property value
###Question 8
#The property value decreases slightly in year 2015 than 2014
#And increases in 2016 again.
#Thi might be due to reduction in the property value
#As the land area increases, the selling amount increases,
###Question 8
#The property value decreases slightly in year 2015 than 2014
#And increases in 2016 again.
#Thi might be due to reduction in the property value
#As the land area increases, the selling amount increases,
#but exceptions are where the established year is early, the rate of the plot is reltively low
###Question 8
#The property value decreases slightly in year 2015 than 2014
#And increases in 2016 again.
#Thi might be due to reduction in the property value
#As the land area increases, the selling amount increases,
#but exceptions are where the established year is early, the rate of the plot is reltively low
#the type of residence according to the sale price of the property
###Question 8
#The property value decreases slightly in year 2015 than 2014
#And increases in 2016 again.
#Thi might be due to reduction in the property value
#As the land area increases, the selling amount increases,
#but exceptions are where the established year is early, the rate of the plot is reltively low
#the type of residence according to the sale price of the property
#As it can be seen from the plots, as the numn\ber of members in the family increases,
###Question 8
#The property value decreases slightly in year 2015 than 2014
#And increases in 2016 again.
#Thi might be due to reduction in the property value
#As the land area increases, the selling amount increases,
#but exceptions are where the established year is early, the rate of the plot is reltively low
#the type of residence according to the sale price of the property
#As it can be seen from the plots, as the numn\ber of members in the family increases,
#the sales amount increases
###Question 8
#The property value decreases slightly in year 2015 than 2014
#And increases in 2016 again.
#Thi might be due to reduction in the property value
#As the land area increases, the selling amount increases,
#but exceptions are where the established year is early, the rate of the plot is reltively low
#the type of residence according to the sale price of the property
#As it can be seen from the plots, as the numn\ber of members in the family increases,
#the sales amount increases
cls
#Set the word directory using setwd()
setwd("C:/Users/kumar/Downloads/Courses/project/R/Assignment4")
#Create a work directory wd (object) Assign a path
wd <- "C:/Users/kumar/Downloads/Courses/project/R/Assignment4"
#Load the package using library() function
library(readr)
#to read the fie from Github assign the UR to an object, url.file
url.file <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Confirmed_archived_0325.csv"
#Read the file using read_csv(url()) function and assign it to a variable confirmed.cases
confirmed.cases <- read_csv(url(url.file))
#Lets put the data frame into another data frame named mydata
mydata <- confirmed.cases
#Download the US shape fie and keep it under the directory
#Load the shape file using the package rgdal
library(rgdal)
USA <- readOGR("C:/R/Assignment4/tl_2019_us_state",
"tl_2019_us_state")
#Open the shape file using the function readOGR("path","folder_name") and assign it to a variable USA
USA <- readOGR("C:/Users/kumar/Downloads/Courses/project/R/Assignment4/tl_2019_us_state",
"tl_2019_us_state")
lower48 <- "https://raw.githubusercontent.com/jasonong/List-of-US-States/master/states.csv"
lower48 <- read_csv(url(lower48))#read the file from URL using read_csv(url())
lower48 <- lower48[lower48$Abbreviation!="HI",] #removes "Hawaii"
lower48 <- lower48[lower48$Abbreviation!="AK",] #removes "Alaska"
lower48 <- lower48[lower48$Abbreviation!="DC",] #removes "District of Columbia"
USA <- merge(x= USA, y=lower48,
by.x = "NAME",
by.y ="State")
#Remove NA after merge from USA
USA <- USA[!is.na(USA@data$Abbreviation),]
plot(USA, col = "skyblue",
main = "My First Map")
covid.data <- mydata[mydata$`Country/Region`=="US",]
covid.data <- merge(x=lower48,
y=covid.data,
by.x="State",
by.y="Province/State",
all.x= T)#all the vlues in lower48 is true
COVID <- covid.data
a<-1
b<-6
for (a in 1:60) {
covid.data[67+a] = covid.data[b+1] -covid.data[b]
a<- a+1
b<- b+1
}
a<-1
b<-6
c<-1
for (a in 1:60) {
for(c in 1:48){
#d <- COVID[b]
if(COVID[c,b]== 0)
{
COVID[c,67+a]= 0
}
else
{
COVID[c,67+a] = ((COVID[c,b+1] - COVID[c,b])/COVID[c,b])*100
}
c <- c+1
}
a <- a+1
b <- b+1
}
USA1 <- USA
covid.data <- covid.data[,-c(6:67)]
i<-1
j<- 6
for (i in 1:60) {
names(covid.data)[j] = names(confirmed.cases)[j]
j <- j+1
i <- i+1
}
#new names
colnames(covid.data)
#Subsetting COVID data
COVID <- COVID[,-c(6:67)]
i<-1
j<- 6
for (i in 1:60) {
names(COVID)[j] = names(confirmed.cases)[j]
j <- j+1
i <- i+1
}
USA <- merge(x=USA,
y=covid.data,
by.x= "NAME",
by.y= "State",
all.x= T)
#plot the shape file for the number of cases in a day to check whether its working
plot(USA, col= USA@data$`3/22/20`)#it uses default colors
#To get nice plots use packages ggplot2 and tmap
library(ggplot2)
library(tmap)
#View the data of USA
USA@data
#view the column headings
names(USA)
#First create a directory confirmed.cases.maps
dir.create("confirmed.cases.maps")
a<-20
for(a in 20:ncol(USA)){ #Dates start from column number 20
map <- tm_shape(USA)+ #tm_shape loads the spatial object
tm_fill(names(USA)[a],
breaks = c(0, 10, 25, 50, 100 ,200, 300, 400, 500, 1000, 2000, 5000, Inf),
style = "fixed",
colorNA = "white",
palette = "Reds")+
tm_borders()+
tm_layout("Increased Confirmed Cases Per day")
tmap_save(map,
#width=1541, #default width
#height=2860, #default height, big plot though...
paste0(wd,"/confirmed.cases.maps/",gsub("/","_",names(USA)[a]),".png"))
}
install.packages("rgeos")
#install.packages("rgeos")
library(rgeos)
a<-20
for(a in 20:ncol(USA)){ #Dates start from column number 20
map <- tm_shape(USA)+ #tm_shape loads the spatial object
tm_fill(names(USA)[a],
breaks = c(0, 10, 25, 50, 100 ,200, 300, 400, 500, 1000, 2000, 5000, Inf),
style = "fixed",
colorNA = "white",
palette = "Reds")+
tm_borders()+
tm_layout("Increased Confirmed Cases Per day")
tmap_save(map,
#width=1541, #default width
#height=2860, #default height, big plot though...
paste0(wd,"/confirmed.cases.maps/",gsub("/","_",names(USA)[a]),".png"))
}
USA1@data
names(USA1)
USA1 <- merge(x=USA1,
y=COVID,
by.x= "NAME",
by.y= "State",
all.x= T)
USA1@data
names(USA1@data)
#First create a directory confirmed.cases.maps
dir.create("Percent.confirmed.cases.maps")
a<- 6
for(a in 20:ncol(USA1)){ #Dates start from column number 20
map1 <- tm_shape(USA1)+ #tm_shape loads the spatial object
tm_fill(names(USA1)[a],
breaks = c(0, 10, 25, 50, 100 ,200, 300, 400, 500, 1000, 2000, 5000, Inf),
style = "fixed",
colorNA = "white",
palette = "Reds")+
tm_borders()+
tm_layout("Percent increase in Confirmed Cases per day")
tmap_save(map1,
#width=1541, #default width
#height=2860, #default height, big plot though...
paste0(wd,"/Percent.confirmed.cases.maps/",gsub("/","_",names(USA1)[a]),".png"))
#Set the word directory using setwd()
setwd("C:/Users/kumar/Downloads/Courses/project/R/Assignment4")
#Create a work directory wd (object) Assign a path
wd <- "C:/Users/kumar/Downloads/Courses/project/R/Assignment4"
#Install a package "readr"to read data from github
#install.packages("readr")
#Load the package using library() function
library(readr)
#to read the fie from Github assign the UR to an object, url.file
url.file <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Confirmed_archived_0325.csv"
#Read the file using read_csv(url()) function and assign it to a variable confirmed.cases
confirmed.cases <- read_csv(url(url.file))
#Lets put the data frame into another data frame named mydata
mydata <- confirmed.cases
#Download the US shape fie and keep it under the directory
#Load the shape file using the package rgdal
library(rgdal)
#Open the shape file using the function readOGR("path","folder_name") and assign it to a variable USA
USA <- readOGR("C:/Users/kumar/Downloads/Courses/project/R/Assignment4/tl_2019_us_state",
"tl_2019_us_state")
lower48 <- "https://raw.githubusercontent.com/jasonong/List-of-US-States/master/states.csv"
lower48 <- read_csv(url(lower48))#read the file from URL using read_csv(url())
lower48 <- lower48[lower48$Abbreviation!="HI",] #removes "Hawaii"
lower48 <- lower48[lower48$Abbreviation!="AK",] #removes "Alaska"
lower48 <- lower48[lower48$Abbreviation!="DC",] #removes "District of Columbia"
USA <- merge(x= USA, y=lower48,
by.x = "NAME",
by.y ="State")
#Remove NA after merge from USA
USA <- USA[!is.na(USA@data$Abbreviation),]
#plot to see the map of lower48 states and label it as "My First Map"
plot(USA, col = "skyblue",
main = "My First Map")
#subset the US data only from mydata and assign it to covid.virus
covid.data <- mydata[mydata$`Country/Region`=="US",]
covid.data <- merge(x=lower48,
y=covid.data,
by.x="State",
by.y="Province/State",
all.x= T)#all the vlues in lower48 is true
COVID <- covid.data
#Creating new columns for Increased number of cases per day and adding the columns
a<-1
b<-6
for (a in 1:60) {
covid.data[67+a] = covid.data[b+1] -covid.data[b]
a<- a+1
b<- b+1
}
a<-1
b<-6
c<-1
for (a in 1:60) {
for(c in 1:48){
#d <- COVID[b]
if(COVID[c,b]== 0)
{
COVID[c,67+a]= 0
}
else
{
COVID[c,67+a] = ((COVID[c,b+1] - COVID[c,b])/COVID[c,b])*100
}
c <- c+1
}
a <- a+1
b <- b+1
}
USA1 <- USA
covid.data <- covid.data[,-c(6:67)]
#Change the names of the newly created columns assign the dates to the names
i<-1
j<- 6
for (i in 1:60) {
names(covid.data)[j] = names(confirmed.cases)[j]
j <- j+1
i <- i+1
}
#new names
colnames(covid.data)
#Subsetting COVID data
COVID <- COVID[,-c(6:67)]
#Change the names of the newly created columns assign the dates to the names
i<-1
j<- 6
for (i in 1:60) {
names(COVID)[j] = names(confirmed.cases)[j]
j <- j+1
i <- i+1
}
USA <- merge(x=USA,
y=covid.data,
by.x= "NAME",
by.y= "State",
all.x= T)
#plot the shape file for the number of cases in a day to check whether its working
plot(USA, col= USA@data$`3/22/20`)#it uses default colors
#To get nice plots use packages ggplot2 and tmap
library(ggplot2)
library(tmap)
#View the data of USA
USA@data
#view the column headings
names(USA)
#First create a directory confirmed.cases.maps
dir.create("confirmed.cases.maps")
#install.packages("rgeos")
library(rgeos)
USA1@data
names(USA1)
USA1 <- merge(x=USA1,
y=COVID,
by.x= "NAME",
by.y= "State",
all.x= T)
USA1@data
#First create a directory confirmed.cases.maps
dir.create("Percent.confirmed.cases.maps")
a<- 6
for(a in 20:ncol(USA1)){ #Dates start from column number 20
map1 <- tm_shape(USA1)+ #tm_shape loads the spatial object
tm_fill(names(USA1)[a],
breaks = c(0, 10, 25, 50, 100 ,200, 300, 400, 500, 1000, 2000, 5000, Inf),
style = "fixed",
colorNA = "white",
palette = "Reds")+
tm_borders()+
tm_layout("Percent increase in Confirmed Cases per day")
tmap_save(map1,
#width=1541, #default width
#height=2860, #default height, big plot though...
paste0(wd,"/Percent.confirmed.cases.maps/",gsub("/","_",names(USA1)[a]),".png"))
}
